{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using Pandas\n",
    "file_path = r\"E:\\Deployment of House price\\archive\\boston.csv\"\n",
    "boston_df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a new DataFrame 'dataset' using the entire 'boston_df'\n",
    "dataset = boston_df.copy()\n",
    "\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'scaler' is the StandardScaler object\n",
    "with open('scaling.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Ridge Regression', Ridge()),\n",
    "    ('Lasso Regression', Lasso()),\n",
    "    ('ElasticNet', ElasticNet()),\n",
    "    ('Decision Tree', DecisionTreeRegressor()),\n",
    "    ('Random Forest', RandomForestRegressor()),\n",
    "    ('Support Vector Machine', SVR()),\n",
    "    ('XGBoost', XGBRegressor()),\n",
    "    ('LightGBM', LGBMRegressor()),\n",
    "    ('K-Nearest Neighbors', KNeighborsRegressor())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 880\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 23.015819\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model                        MSE    R-Squared\n",
      "----------------------  --------  -----------\n",
      "Linear Regression       21.5174      0.711226\n",
      "Ridge Regression        21.5487      0.710807\n",
      "Lasso Regression        26.5325      0.643922\n",
      "ElasticNet              27.4901      0.63107\n",
      "Decision Tree           18.1084      0.756977\n",
      "Random Forest            9.25626     0.875777\n",
      "Support Vector Machine  25.9572      0.651643\n",
      "XGBoost                  9.46656     0.872954\n",
      "LightGBM                11.7014      0.842962\n",
      "K-Nearest Neighbors     18.835       0.747225\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    # Fit the model directly\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    evaluation = (mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred))\n",
    "\n",
    "    results.append([name, evaluation[0], evaluation[1]])\n",
    "\n",
    "\n",
    "# Display results in a table\n",
    "headers = [\"Model\", \"MSE\", \"R-Squared\"]\n",
    "print(tabulate(results, headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                        MSE    R-Squared\n",
      "----------------------  --------  -----------\n",
      "Linear Regression       21.5174      0.711226\n",
      "Ridge Regression        21.5487      0.710807\n",
      "Lasso Regression        26.5325      0.643922\n",
      "ElasticNet              27.4901      0.63107\n",
      "Decision Tree           18.1084      0.756977\n",
      "Random Forest            9.25626     0.875777\n",
      "Support Vector Machine  25.9572      0.651643\n",
      "XGBoost                  9.46656     0.872954\n",
      "LightGBM                11.7014      0.842962\n",
      "K-Nearest Neighbors     18.835       0.747225\n",
      "\n",
      "Models with RMSE closest to 1:\n",
      "Model               MSE    R-Squared\n",
      "-------------  --------  -----------\n",
      "Random Forest   9.25626     0.875777\n",
      "XGBoost         9.46656     0.872954\n",
      "LightGBM       11.7014      0.842962\n"
     ]
    }
   ],
   "source": [
    "# Display results for all models\n",
    "headers = [\"Model\", \"MSE\", \"R-Squared\"]\n",
    "print(tabulate(results, headers=headers))\n",
    "\n",
    "# Sort models by closeness to RMSE value of 1\n",
    "results.sort(key=lambda x: abs(np.sqrt(x[1]) - 1))\n",
    "\n",
    "# Filter models with RMSE closest to 1\n",
    "close_models = [(name, mse, r_squared) for name, mse, r_squared in results]\n",
    "\n",
    "# Print models with RMSE closest to 1\n",
    "if close_models:\n",
    "    print(\"\\nModels with RMSE closest to 1:\")\n",
    "    print(tabulate(close_models[:3], headers=headers))\n",
    "else:\n",
    "    print(\"No models found within the specified RMSE threshold.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack the models to obtain better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;random_forest&#x27;,\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     (&#x27;xgboost&#x27;,\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   device=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   grow...\n",
       "                                                                   multi_strategy=None,\n",
       "                                                                   n_estimators=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={&#x27;random_forest__max_depth&#x27;: [10, 20],\n",
       "                         &#x27;random_forest__n_estimators&#x27;: [100, 150],\n",
       "                         &#x27;xgboost__learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;xgboost__max_depth&#x27;: [3, 5],\n",
       "                         &#x27;xgboost__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;random_forest&#x27;,\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     (&#x27;xgboost&#x27;,\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   device=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   grow...\n",
       "                                                                   multi_strategy=None,\n",
       "                                                                   n_estimators=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={&#x27;random_forest__max_depth&#x27;: [10, 20],\n",
       "                         &#x27;random_forest__n_estimators&#x27;: [100, 150],\n",
       "                         &#x27;xgboost__learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;xgboost__max_depth&#x27;: [3, 5],\n",
       "                         &#x27;xgboost__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;random_forest&#x27;, RandomForestRegressor()),\n",
       "                              (&#x27;xgboost&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type...\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=None, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...))],\n",
       "                  final_estimator=LinearRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>random_forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[('random_forest',\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     ('xgboost',\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   device=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   grow...\n",
       "                                                                   multi_strategy=None,\n",
       "                                                                   n_estimators=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={'random_forest__max_depth': [10, 20],\n",
       "                         'random_forest__n_estimators': [100, 150],\n",
       "                         'xgboost__learning_rate': [0.1, 0.01],\n",
       "                         'xgboost__max_depth': [3, 5],\n",
       "                         'xgboost__n_estimators': [100, 150]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base models\n",
    "base_models = [\n",
    "    ('random_forest', RandomForestRegressor()),\n",
    "    ('xgboost', XGBRegressor())\n",
    "]\n",
    "\n",
    "# Create a stacking regressor with the specified base models and a final estimator (Linear Regression)\n",
    "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "# Define a more limited parameter grid for tuning\n",
    "param_grid = {\n",
    "    'random_forest__n_estimators': [100, 150],\n",
    "    'random_forest__max_depth': [10, 20],\n",
    "    'xgboost__n_estimators': [100, 150],\n",
    "    'xgboost__max_depth': [3, 5],\n",
    "    'xgboost__learning_rate': [0.1, 0.01],\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(stacking_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Combination:\n",
      "Parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 150, 'xgboost__learning_rate': 0.1, 'xgboost__max_depth': 3, 'xgboost__n_estimators': 150}\n",
      "Mean Test Score (neg MSE): -12.133298514181336\n",
      "Final Metrics for the Best Combination:\n",
      "MSE: 8.174149959051263\n",
      "R^2 Score: 0.8902991494749243\n"
     ]
    }
   ],
   "source": [
    "# Get the best combination based on the mean_test_score\n",
    "best_combination_index = grid_search.best_index_\n",
    "best_combination_params = grid_search.cv_results_['params'][best_combination_index]\n",
    "best_combination_mean_test_score = grid_search.cv_results_['mean_test_score'][best_combination_index]\n",
    "\n",
    "# Set the best parameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_combination_params)\n",
    "\n",
    "# Fit the stacking regressor with the best parameters on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set with the best stacking regressor\n",
    "y_pred_stacking = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Calculate final metrics\n",
    "mse_stacking = mean_squared_error(y_test, y_pred_stacking)\n",
    "r2_stacking = r2_score(y_test, y_pred_stacking)\n",
    "\n",
    "# Print the best combination and its metrics\n",
    "print(\"\\nBest Combination:\")\n",
    "print(f\"Parameters: {best_combination_params}\")\n",
    "print(f\"Mean Test Score (neg MSE): {best_combination_mean_test_score}\")\n",
    "print(\"Final Metrics for the Best Combination:\")\n",
    "print(\"MSE:\", mse_stacking)\n",
    "print(\"R^2 Score:\", r2_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted\n",
      "173    23.6  23.458310\n",
      "274    32.4  31.339928\n",
      "491    13.6  16.165257\n",
      "72     22.8  24.001468\n",
      "452    16.1  17.548715\n",
      "..      ...        ...\n",
      "441    17.1  12.983459\n",
      "23     14.5  14.123404\n",
      "225    50.0  44.636407\n",
      "433    14.3  16.038332\n",
      "447    12.6  16.964403\n",
      "\n",
      "[152 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choose the best combination of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the best hyperparameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_params)\n",
    "\n",
    "# Fit the stacking regressor on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_stacking = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Compare predictions with original values\n",
    "predictions_comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_stacking})\n",
    "print(predictions_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling The Model file For Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best combination of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the best hyperparameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_params)\n",
    "\n",
    "# Fit the stacking regressor on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Save the model with the best parameters\n",
    "pickle.dump(stacking_regressor, open('newregmodel.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Validation Set: [23.60801464 31.40781352 16.12292437 24.00812409 17.74124449 22.59786891\n",
      " 18.13232142 14.26852207 21.07148012 21.05646134 20.26716197 18.82223676\n",
      "  6.95155624 21.74507647 19.8717516  24.77218925 19.38279486  9.22413199\n",
      " 45.82067146 16.67865552 24.30989814 25.23255041 13.7387978  20.39517906\n",
      " 15.20560676 16.21230116 22.10231906 14.09970588 20.14057186 21.39536098\n",
      " 19.69971694 23.59212376 19.96673778 20.41902005 14.67024883 16.16741346\n",
      " 33.44634821 19.41191079 21.55157281 23.82891366 17.28146175 29.749704\n",
      " 45.0666019  20.37628201 22.56855204 14.37370149 16.47919933 23.59472399\n",
      " 18.02893305 27.66725379 20.93298492 37.59462461 16.2467028  25.69506731\n",
      " 48.56168606 21.78979643 15.77435826 32.19097204 21.87631071 18.06872176\n",
      " 22.0450723  34.40883727 31.38999044 19.03759403 23.67039386 18.61914289\n",
      " 14.06527324 23.80127967 28.39782145 14.67120644 21.38354716 25.69902472\n",
      " 11.57514812 21.45751985 22.46371364  4.95318989 20.87461998 45.06828043\n",
      " 10.88513791 12.62339508 22.23368007 11.68958685 19.194227   10.69861004\n",
      " 19.97517423 26.65734813 16.11387692 23.81993674 25.81285283 17.00793411\n",
      " 22.19961582  8.68514409 19.84555849 19.41339294 22.81322402 20.01174734\n",
      " 40.66295778 10.21724735 12.71298976 10.93205109 20.17080294 23.407832\n",
      " 13.84538566 20.59508483 19.96993838 10.63040708 18.97329374 26.50562048\n",
      " 20.11658197 24.21367916  8.25649831 13.41173881 22.19537266 25.70592921\n",
      " 32.86950151 16.40955957 41.92175297 15.28044851 20.79073977 24.46163053\n",
      " 19.07573701 24.18991583  5.63937518 20.71905667 23.80962522 22.44366536\n",
      " 22.74520058 40.62785429 16.42353033 47.43203635 17.10816565 23.56129762\n",
      " 19.45212737 18.91600029 13.4121344  20.49481451 21.20073876 30.93457766\n",
      " 29.0009184  15.92919097 17.26724749 24.97543857 20.24321027 18.75497844\n",
      "  6.91391324 21.28442254 17.00112789 12.99737809 14.02735752 44.73873274\n",
      " 16.2863581  17.18948954]\n"
     ]
    }
   ],
   "source": [
    "# Load the StackingRegressor model from the existing pickled file\n",
    "loaded_stacking_regressor = pickle.load(open('newregmodel.pkl', 'rb'))\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_validation = loaded_stacking_regressor.predict(X_test)\n",
    "\n",
    "# Save the new model with a different pickle name\n",
    "new_pickle_name = 'new_regmodel.pkl'\n",
    "pickle.dump(loaded_stacking_regressor, open(new_pickle_name, 'wb'))\n",
    "\n",
    "# Print the predictions (y_pred_validation) or use them as needed\n",
    "print(\"Predictions on Validation Set:\", y_pred_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
