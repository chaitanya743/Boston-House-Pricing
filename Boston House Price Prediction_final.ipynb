{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using Pandas\n",
    "file_path = r\"E:\\Deployment of House price\\archive\\boston.csv\"\n",
    "boston_df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a new DataFrame 'dataset' using the entire 'boston_df'\n",
    "dataset = boston_df.copy()\n",
    "\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'scaler' is the StandardScaler object\n",
    "with open('scaling.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Ridge Regression', Ridge()),\n",
    "    ('Lasso Regression', Lasso()),\n",
    "    ('ElasticNet', ElasticNet()),\n",
    "    ('Decision Tree', DecisionTreeRegressor()),\n",
    "    ('Random Forest', RandomForestRegressor()),\n",
    "    ('Support Vector Machine', SVR()),\n",
    "    ('XGBoost', XGBRegressor()),\n",
    "    ('LightGBM', LGBMRegressor()),\n",
    "    ('K-Nearest Neighbors', KNeighborsRegressor())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 880\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 23.015819\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model                        MSE    R-Squared\n",
      "----------------------  --------  -----------\n",
      "Linear Regression       21.5174      0.711226\n",
      "Ridge Regression        21.5487      0.710807\n",
      "Lasso Regression        26.5325      0.643922\n",
      "ElasticNet              27.4901      0.63107\n",
      "Decision Tree           11.062       0.851542\n",
      "Random Forest            9.11007     0.877739\n",
      "Support Vector Machine  25.9572      0.651643\n",
      "XGBoost                  9.46656     0.872954\n",
      "LightGBM                11.7014      0.842962\n",
      "K-Nearest Neighbors     18.835       0.747225\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    if name == 'Neural Network':\n",
    "        model.compile(optimizer=Adam(lr=0.0001), loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "        history = model.fit(X_train, y_train, epochs=2000, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "        evaluation = model.evaluate(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        r_squared = r2_score(y_test, y_pred)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        evaluation = (mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred))\n",
    "\n",
    "    results.append([name, evaluation[0], evaluation[1]])\n",
    "\n",
    "# Display results in a table\n",
    "headers = [\"Model\", \"MSE\", \"R-Squared\"]\n",
    "print(tabulate(results, headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                        MSE    R-Squared\n",
      "----------------------  --------  -----------\n",
      "Linear Regression       21.5174      0.711226\n",
      "Ridge Regression        21.5487      0.710807\n",
      "Lasso Regression        26.5325      0.643922\n",
      "ElasticNet              27.4901      0.63107\n",
      "Decision Tree           11.062       0.851542\n",
      "Random Forest            9.11007     0.877739\n",
      "Support Vector Machine  25.9572      0.651643\n",
      "XGBoost                  9.46656     0.872954\n",
      "LightGBM                11.7014      0.842962\n",
      "K-Nearest Neighbors     18.835       0.747225\n",
      "\n",
      "Models with RMSE closest to 1:\n",
      "Model               MSE    R-Squared\n",
      "-------------  --------  -----------\n",
      "Random Forest   9.11007     0.877739\n",
      "XGBoost         9.46656     0.872954\n",
      "Decision Tree  11.062       0.851542\n"
     ]
    }
   ],
   "source": [
    "# Display results for all models\n",
    "headers = [\"Model\", \"MSE\", \"R-Squared\"]\n",
    "print(tabulate(results, headers=headers))\n",
    "\n",
    "# Sort models by closeness to RMSE value of 1\n",
    "results.sort(key=lambda x: abs(np.sqrt(x[1]) - 1))\n",
    "\n",
    "# Filter models with RMSE closest to 1\n",
    "close_models = [(name, mse, r_squared) for name, mse, r_squared in results]\n",
    "\n",
    "# Print models with RMSE closest to 1\n",
    "if close_models:\n",
    "    print(\"\\nModels with RMSE closest to 1:\")\n",
    "    print(tabulate(close_models[:3], headers=headers))\n",
    "else:\n",
    "    print(\"No models found within the specified RMSE threshold.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack the models to obtain better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;random_forest&#x27;,\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     (&#x27;xgboost&#x27;,\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   device=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   grow...\n",
       "                                                                   multi_strategy=None,\n",
       "                                                                   n_estimators=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={&#x27;random_forest__max_depth&#x27;: [10, 20],\n",
       "                         &#x27;random_forest__n_estimators&#x27;: [100, 150],\n",
       "                         &#x27;xgboost__learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;xgboost__max_depth&#x27;: [3, 5],\n",
       "                         &#x27;xgboost__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;random_forest&#x27;,\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     (&#x27;xgboost&#x27;,\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   device=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   grow...\n",
       "                                                                   multi_strategy=None,\n",
       "                                                                   n_estimators=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={&#x27;random_forest__max_depth&#x27;: [10, 20],\n",
       "                         &#x27;random_forest__n_estimators&#x27;: [100, 150],\n",
       "                         &#x27;xgboost__learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;xgboost__max_depth&#x27;: [3, 5],\n",
       "                         &#x27;xgboost__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;random_forest&#x27;, RandomForestRegressor()),\n",
       "                              (&#x27;xgboost&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type...\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=None, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...))],\n",
       "                  final_estimator=LinearRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>random_forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[('random_forest',\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     ('xgboost',\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   device=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   grow...\n",
       "                                                                   multi_strategy=None,\n",
       "                                                                   n_estimators=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={'random_forest__max_depth': [10, 20],\n",
       "                         'random_forest__n_estimators': [100, 150],\n",
       "                         'xgboost__learning_rate': [0.1, 0.01],\n",
       "                         'xgboost__max_depth': [3, 5],\n",
       "                         'xgboost__n_estimators': [100, 150]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base models\n",
    "base_models = [\n",
    "    ('random_forest', RandomForestRegressor()),\n",
    "    ('xgboost', XGBRegressor())\n",
    "]\n",
    "\n",
    "# Create a stacking regressor with the specified base models and a final estimator (Linear Regression)\n",
    "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "# Define a more limited parameter grid for tuning\n",
    "param_grid = {\n",
    "    'random_forest__n_estimators': [100, 150],\n",
    "    'random_forest__max_depth': [10, 20],\n",
    "    'xgboost__n_estimators': [100, 150],\n",
    "    'xgboost__max_depth': [3, 5],\n",
    "    'xgboost__learning_rate': [0.1, 0.01],\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(stacking_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Combination:\n",
      "Parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 100, 'xgboost__learning_rate': 0.1, 'xgboost__max_depth': 3, 'xgboost__n_estimators': 150}\n",
      "Mean Test Score (neg MSE): -12.029578812790536\n",
      "Final Metrics for the Best Combination:\n",
      "MSE: 8.180223868211112\n",
      "R^2 Score: 0.8902176348215126\n"
     ]
    }
   ],
   "source": [
    "# Get the best combination based on the mean_test_score\n",
    "best_combination_index = grid_search.best_index_\n",
    "best_combination_params = grid_search.cv_results_['params'][best_combination_index]\n",
    "best_combination_mean_test_score = grid_search.cv_results_['mean_test_score'][best_combination_index]\n",
    "\n",
    "# Set the best parameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_combination_params)\n",
    "\n",
    "# Fit the stacking regressor with the best parameters on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set with the best stacking regressor\n",
    "y_pred_stacking = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Calculate final metrics\n",
    "mse_stacking = mean_squared_error(y_test, y_pred_stacking)\n",
    "r2_stacking = r2_score(y_test, y_pred_stacking)\n",
    "\n",
    "# Print the best combination and its metrics\n",
    "print(\"\\nBest Combination:\")\n",
    "print(f\"Parameters: {best_combination_params}\")\n",
    "print(f\"Mean Test Score (neg MSE): {best_combination_mean_test_score}\")\n",
    "print(\"Final Metrics for the Best Combination:\")\n",
    "print(\"MSE:\", mse_stacking)\n",
    "print(\"R^2 Score:\", r2_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted\n",
      "173    23.6  23.509431\n",
      "274    32.4  31.466268\n",
      "491    13.6  16.090778\n",
      "72     22.8  24.013067\n",
      "452    16.1  17.649051\n",
      "..      ...        ...\n",
      "441    17.1  12.985337\n",
      "23     14.5  14.072877\n",
      "225    50.0  44.787992\n",
      "433    14.3  16.138062\n",
      "447    12.6  17.041544\n",
      "\n",
      "[152 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choose the best combination of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the best hyperparameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_params)\n",
    "\n",
    "# Fit the stacking regressor on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_stacking = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Compare predictions with original values\n",
    "predictions_comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_stacking})\n",
    "print(predictions_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling The Model file For Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best combination of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the best hyperparameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_params)\n",
    "\n",
    "# Fit the stacking regressor on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Save the model with the best parameters\n",
    "pickle.dump(stacking_regressor, open('newregmodel.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Validation Set: [23.61008418 31.40600403 16.12440082 24.0085797  17.74377837 22.59960023\n",
      " 18.12846321 14.26959303 21.07169744 21.05692898 20.26895876 18.82043829\n",
      "  6.95340707 21.74563915 19.87329582 24.76990748 19.38474298  9.22871425\n",
      " 45.81703446 16.68204578 24.30918815 25.23497579 13.73895901 20.38745291\n",
      " 15.20656098 16.21576852 22.10390681 14.10237274 20.14234513 21.39679662\n",
      " 19.70023667 23.59272484 19.94155624 20.42028844 14.67366169 16.16786281\n",
      " 33.44231584 19.41215791 21.55262573 23.82779009 17.27797716 29.74951169\n",
      " 45.06207988 20.37826897 22.56943334 14.37617034 16.48219331 23.59257649\n",
      " 18.02731713 27.66486473 20.93262989 37.60125776 16.24447421 25.69307823\n",
      " 48.56398461 21.78983353 15.77513832 32.18733706 21.87610577 18.06240602\n",
      " 22.03627446 34.40883896 31.39096524 19.03734975 23.66217428 18.62410789\n",
      " 14.06750468 23.80282493 28.39618806 14.67132833 21.38504846 25.69103464\n",
      " 11.58059292 21.45501104 22.4638325   4.95203812 20.87689786 45.06187296\n",
      " 10.88775919 12.62578527 22.23586205 11.69132412 19.1930095  10.70503833\n",
      " 19.9732887  26.65543116 16.11458506 23.82104819 25.81789969 17.00626628\n",
      " 22.20048295  8.69179586 19.84603488 19.41292546 22.80792196 20.0122546\n",
      " 40.66786799 10.21562027 12.71531602 10.93079803 20.17020198 23.40771442\n",
      " 13.84841193 20.59583332 19.97004482 10.62748703 18.97266743 26.50912916\n",
      " 20.11649584 24.21544264  8.25695859 13.40707469 22.19384238 25.70769846\n",
      " 32.87022506 16.41474474 41.92079259 15.27909238 20.79443489 24.46198477\n",
      " 19.0750845  24.18992234  5.63779439 20.71922803 23.8077409  22.44521366\n",
      " 22.74262407 40.63937254 16.4227061  47.43261879 17.11377593 23.56158761\n",
      " 19.45132317 18.91664576 13.41284735 20.49435229 21.20259196 30.93275805\n",
      " 29.00055319 15.92660741 17.26346419 24.97442801 20.24328233 18.7554457\n",
      "  6.91785815 21.28375274 17.00151186 12.99749014 14.026443   44.73832273\n",
      " 16.2895645  17.19319336]\n"
     ]
    }
   ],
   "source": [
    "# Load the StackingRegressor model from the existing pickled file\n",
    "loaded_stacking_regressor = pickle.load(open('newregmodel.pkl', 'rb'))\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_validation = loaded_stacking_regressor.predict(X_test)\n",
    "\n",
    "# Save the new model with a different pickle name\n",
    "new_pickle_name = 'new_regmodel.pkl'\n",
    "pickle.dump(loaded_stacking_regressor, open(new_pickle_name, 'wb'))\n",
    "\n",
    "# Print the predictions (y_pred_validation) or use them as needed\n",
    "print(\"Predictions on Validation Set:\", y_pred_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
