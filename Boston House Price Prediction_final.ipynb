{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using Pandas\n",
    "file_path = r\"E:\\Deployment of House price\\archive\\boston.csv\"\n",
    "boston_df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a new DataFrame 'dataset' using the entire 'boston_df'\n",
    "dataset = boston_df.copy()\n",
    "\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'scaler' is the StandardScaler object\n",
    "with open('scaling.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Neural Network', Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])),\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Ridge Regression', Ridge()),\n",
    "    ('Lasso Regression', Lasso()),\n",
    "    ('ElasticNet', ElasticNet()),\n",
    "    ('Decision Tree', DecisionTreeRegressor()),\n",
    "    ('Random Forest', RandomForestRegressor()),\n",
    "    ('Support Vector Machine', SVR()),\n",
    "    ('XGBoost', XGBRegressor()),\n",
    "    ('LightGBM', LGBMRegressor()),\n",
    "    ('K-Nearest Neighbors', KNeighborsRegressor())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91756\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 11.3703 - mae: 2.2062 - mse: 11.3703\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 880\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 23.015819\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model                        MSE    R-Squared\n",
      "----------------------  --------  -----------\n",
      "Neural Network          11.3703      2.2062\n",
      "Linear Regression       21.5174      0.711226\n",
      "Ridge Regression        21.5487      0.710807\n",
      "Lasso Regression        26.5325      0.643922\n",
      "ElasticNet              27.4901      0.63107\n",
      "Decision Tree           18.5411      0.75117\n",
      "Random Forest            9.71771     0.869584\n",
      "Support Vector Machine  25.9572      0.651643\n",
      "XGBoost                  9.57647     0.871479\n",
      "LightGBM                11.7014      0.842962\n",
      "K-Nearest Neighbors     18.835       0.747225\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    if name == 'Neural Network':\n",
    "        model.compile(optimizer=Adam(lr=0.0001), loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "        history = model.fit(X_train, y_train, epochs=2000, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "        evaluation = model.evaluate(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        r_squared = r2_score(y_test, y_pred)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        evaluation = (mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred))\n",
    "\n",
    "    results.append([name, evaluation[0], evaluation[1]])\n",
    "\n",
    "# Display results in a table\n",
    "headers = [\"Model\", \"MSE\", \"R-Squared\"]\n",
    "print(tabulate(results, headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                        MSE    R-Squared\n",
      "----------------------  --------  -----------\n",
      "Neural Network          11.3703      2.2062\n",
      "Linear Regression       21.5174      0.711226\n",
      "Ridge Regression        21.5487      0.710807\n",
      "Lasso Regression        26.5325      0.643922\n",
      "ElasticNet              27.4901      0.63107\n",
      "Decision Tree           18.5411      0.75117\n",
      "Random Forest            9.71771     0.869584\n",
      "Support Vector Machine  25.9572      0.651643\n",
      "XGBoost                  9.57647     0.871479\n",
      "LightGBM                11.7014      0.842962\n",
      "K-Nearest Neighbors     18.835       0.747225\n",
      "\n",
      "Models with RMSE closest to 1:\n",
      "Model                MSE    R-Squared\n",
      "--------------  --------  -----------\n",
      "XGBoost          9.57647     0.871479\n",
      "Random Forest    9.71771     0.869584\n",
      "Neural Network  11.3703      2.2062\n"
     ]
    }
   ],
   "source": [
    "# Display results for all models\n",
    "headers = [\"Model\", \"MSE\", \"R-Squared\"]\n",
    "print(tabulate(results, headers=headers))\n",
    "\n",
    "# Sort models by closeness to RMSE value of 1\n",
    "results.sort(key=lambda x: abs(np.sqrt(x[1]) - 1))\n",
    "\n",
    "# Filter models with RMSE closest to 1\n",
    "close_models = [(name, mse, r_squared) for name, mse, r_squared in results]\n",
    "\n",
    "# Print models with RMSE closest to 1\n",
    "if close_models:\n",
    "    print(\"\\nModels with RMSE closest to 1:\")\n",
    "    print(tabulate(close_models[:3], headers=headers))\n",
    "else:\n",
    "    print(\"No models found within the specified RMSE threshold.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack the models to obtain better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;random_forest&#x27;,\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     (&#x27;xgboost&#x27;,\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   gpu_id=None,\n",
       "                                                                   grow...\n",
       "                                                                   monotone_constraints=None,\n",
       "                                                                   n_estimators=100,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   predictor=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={&#x27;random_forest__max_depth&#x27;: [10, 20],\n",
       "                         &#x27;random_forest__n_estimators&#x27;: [100, 150],\n",
       "                         &#x27;xgboost__learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;xgboost__max_depth&#x27;: [3, 5],\n",
       "                         &#x27;xgboost__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;random_forest&#x27;,\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     (&#x27;xgboost&#x27;,\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   gpu_id=None,\n",
       "                                                                   grow...\n",
       "                                                                   monotone_constraints=None,\n",
       "                                                                   n_estimators=100,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   predictor=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={&#x27;random_forest__max_depth&#x27;: [10, 20],\n",
       "                         &#x27;random_forest__n_estimators&#x27;: [100, 150],\n",
       "                         &#x27;xgboost__learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;xgboost__max_depth&#x27;: [3, 5],\n",
       "                         &#x27;xgboost__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;random_forest&#x27;, RandomForestRegressor()),\n",
       "                              (&#x27;xgboost&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...))],\n",
       "                  final_estimator=LinearRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>random_forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[('random_forest',\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     ('xgboost',\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   gpu_id=None,\n",
       "                                                                   grow...\n",
       "                                                                   monotone_constraints=None,\n",
       "                                                                   n_estimators=100,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   predictor=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={'random_forest__max_depth': [10, 20],\n",
       "                         'random_forest__n_estimators': [100, 150],\n",
       "                         'xgboost__learning_rate': [0.1, 0.01],\n",
       "                         'xgboost__max_depth': [3, 5],\n",
       "                         'xgboost__n_estimators': [100, 150]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base models\n",
    "base_models = [\n",
    "    ('random_forest', RandomForestRegressor()),\n",
    "    ('xgboost', XGBRegressor())\n",
    "]\n",
    "\n",
    "# Create a stacking regressor with the specified base models and a final estimator (Linear Regression)\n",
    "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "# Define a more limited parameter grid for tuning\n",
    "param_grid = {\n",
    "    'random_forest__n_estimators': [100, 150],\n",
    "    'random_forest__max_depth': [10, 20],\n",
    "    'xgboost__n_estimators': [100, 150],\n",
    "    'xgboost__max_depth': [3, 5],\n",
    "    'xgboost__learning_rate': [0.1, 0.01],\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(stacking_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Combination:\n",
      "Parameters: {'random_forest__max_depth': 20, 'random_forest__n_estimators': 100, 'xgboost__learning_rate': 0.1, 'xgboost__max_depth': 3, 'xgboost__n_estimators': 150}\n",
      "Mean Test Score (neg MSE): -11.929834509741003\n",
      "Final Metrics for the Best Combination:\n",
      "MSE: 9.024429949021195\n",
      "R^2 Score: 0.8788880010923491\n"
     ]
    }
   ],
   "source": [
    "# Get the best combination based on the mean_test_score\n",
    "best_combination_index = grid_search.best_index_\n",
    "best_combination_params = grid_search.cv_results_['params'][best_combination_index]\n",
    "best_combination_mean_test_score = grid_search.cv_results_['mean_test_score'][best_combination_index]\n",
    "\n",
    "# Set the best parameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_combination_params)\n",
    "\n",
    "# Fit the stacking regressor with the best parameters on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set with the best stacking regressor\n",
    "y_pred_stacking = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Calculate final metrics\n",
    "mse_stacking = mean_squared_error(y_test, y_pred_stacking)\n",
    "r2_stacking = r2_score(y_test, y_pred_stacking)\n",
    "\n",
    "# Print the best combination and its metrics\n",
    "print(\"\\nBest Combination:\")\n",
    "print(f\"Parameters: {best_combination_params}\")\n",
    "print(f\"Mean Test Score (neg MSE): {best_combination_mean_test_score}\")\n",
    "print(\"Final Metrics for the Best Combination:\")\n",
    "print(\"MSE:\", mse_stacking)\n",
    "print(\"R^2 Score:\", r2_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted\n",
      "173    23.6  23.550480\n",
      "274    32.4  32.198074\n",
      "491    13.6  15.699641\n",
      "72     22.8  23.610766\n",
      "452    16.1  17.561221\n",
      "..      ...        ...\n",
      "441    17.1  12.889954\n",
      "23     14.5  14.074192\n",
      "225    50.0  44.318905\n",
      "433    14.3  15.563411\n",
      "447    12.6  16.478708\n",
      "\n",
      "[152 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choose the best combination of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the best hyperparameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_params)\n",
    "\n",
    "# Fit the stacking regressor on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_stacking = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Compare predictions with original values\n",
    "predictions_comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_stacking})\n",
    "print(predictions_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling The Model file For Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best combination of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the best hyperparameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_params)\n",
    "\n",
    "# Fit the stacking regressor on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Save the model with the best parameters\n",
    "pickle.dump(stacking_regressor, open('newregmodel.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Validation Set: [23.52552528 32.36962568 15.67104895 23.57480966 17.5137104  22.54282983\n",
      " 18.19964208 13.99038576 20.8701912  21.21487172 20.45106833 18.55533192\n",
      "  8.96299899 21.90066038 20.14704567 25.02905101 19.27730862  9.93028659\n",
      " 46.59943392 16.23673783 24.20440479 25.03789791 13.80104415 20.81110842\n",
      " 15.95545536 16.53801477 21.97741932 13.31371236 19.91073333 21.391\n",
      " 19.65848025 23.70723487 23.60437502 20.50604325 14.38435921 16.86322676\n",
      " 33.51466483 19.62476095 21.82105274 23.50097488 17.71965469 30.02671107\n",
      " 45.16668515 19.93343015 22.55530281 15.24299576 16.23594869 23.58214381\n",
      " 18.44870189 27.02727137 20.66684782 36.7665558  16.75196108 25.87198678\n",
      " 48.86774704 21.68607571 16.61201876 32.13197971 22.27939734 18.75395745\n",
      " 22.75552239 35.37543731 32.4971282  20.03329676 25.52665909 16.92402613\n",
      " 14.43613425 23.34770096 29.08857576 14.3602627  20.88033245 28.95765304\n",
      "  9.9204531  20.85717982 22.45091039  6.97027702 20.69558889 45.57353054\n",
      " 11.37700939 11.97922385 21.94175555 11.77222528 19.16739255  9.94669793\n",
      " 20.04452489 27.21817689 16.1041878  23.86803295 25.1627215  17.40046961\n",
      " 21.63720863  8.10409025 19.58916283 19.55648083 22.96763277 19.7188963\n",
      " 36.76584281 11.53198366 12.87227229 11.27897607 20.25639984 23.92312302\n",
      " 13.53546902 20.55054294 20.21737651 12.29667071 19.25465443 25.88747528\n",
      " 20.58959288 23.83731701  8.93881241 13.03283336 22.1119888  25.54440115\n",
      " 32.77888153 15.10681763 43.22249876 15.85732975 20.59889172 24.21723883\n",
      " 19.53766424 24.01286259  5.91910417 20.78745977 23.47483546 22.51649752\n",
      " 22.31950698 40.39421946 17.33592718 47.1598444  16.20840245 23.66205593\n",
      " 19.33843923 18.76088016 13.41313571 19.58344388 21.52135949 32.20449433\n",
      " 29.67921207 16.3620235  17.6304523  25.3804201  19.62407081 17.56314725\n",
      "  7.438258   20.98530339 18.32440298 12.89091271 13.95967997 44.42639757\n",
      " 15.54526008 16.45665447]\n"
     ]
    }
   ],
   "source": [
    "# Load the StackingRegressor model from the existing pickled file\n",
    "loaded_stacking_regressor = pickle.load(open('newregmodel.pkl', 'rb'))\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_validation = loaded_stacking_regressor.predict(X_test)\n",
    "\n",
    "# Save the new model with a different pickle name\n",
    "new_pickle_name = 'new_regmodel.pkl'\n",
    "pickle.dump(loaded_stacking_regressor, open(new_pickle_name, 'wb'))\n",
    "\n",
    "# Print the predictions (y_pred_validation) or use them as needed\n",
    "print(\"Predictions on Validation Set:\", y_pred_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
