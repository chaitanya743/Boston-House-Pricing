{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using Pandas\n",
    "file_path = r\"E:\\Deployment of House price\\archive\\boston.csv\"\n",
    "boston_df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a new DataFrame 'dataset' using the entire 'boston_df'\n",
    "dataset = boston_df.copy()\n",
    "\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'scaler' is the StandardScaler object\n",
    "with open('scaling.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Ridge Regression', Ridge()),\n",
    "    ('Lasso Regression', Lasso()),\n",
    "    ('ElasticNet', ElasticNet()),\n",
    "    ('Decision Tree', DecisionTreeRegressor()),\n",
    "    ('Random Forest', RandomForestRegressor()),\n",
    "    ('Support Vector Machine', SVR()),\n",
    "    ('XGBoost', XGBRegressor()),\n",
    "    ('LightGBM', LGBMRegressor()),\n",
    "    ('K-Nearest Neighbors', KNeighborsRegressor())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 880\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 23.015819\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model                        MSE    R-Squared\n",
      "----------------------  --------  -----------\n",
      "Linear Regression       21.5174      0.711226\n",
      "Ridge Regression        21.5487      0.710807\n",
      "Lasso Regression        26.5325      0.643922\n",
      "ElasticNet              27.4901      0.63107\n",
      "Decision Tree           19.6668      0.736062\n",
      "Random Forest            9.60433     0.871106\n",
      "Support Vector Machine  25.9572      0.651643\n",
      "XGBoost                  9.46656     0.872954\n",
      "LightGBM                11.7014      0.842962\n",
      "K-Nearest Neighbors     18.835       0.747225\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    # Fit the model directly\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    evaluation = (mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred))\n",
    "\n",
    "    results.append([name, evaluation[0], evaluation[1]])\n",
    "\n",
    "\n",
    "# Display results in a table\n",
    "headers = [\"Model\", \"MSE\", \"R-Squared\"]\n",
    "print(tabulate(results, headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                        MSE    R-Squared\n",
      "----------------------  --------  -----------\n",
      "Linear Regression       21.5174      0.711226\n",
      "Ridge Regression        21.5487      0.710807\n",
      "Lasso Regression        26.5325      0.643922\n",
      "ElasticNet              27.4901      0.63107\n",
      "Decision Tree           19.6668      0.736062\n",
      "Random Forest            9.60433     0.871106\n",
      "Support Vector Machine  25.9572      0.651643\n",
      "XGBoost                  9.46656     0.872954\n",
      "LightGBM                11.7014      0.842962\n",
      "K-Nearest Neighbors     18.835       0.747225\n",
      "\n",
      "Models with RMSE closest to 1:\n",
      "Model               MSE    R-Squared\n",
      "-------------  --------  -----------\n",
      "XGBoost         9.46656     0.872954\n",
      "Random Forest   9.60433     0.871106\n",
      "LightGBM       11.7014      0.842962\n"
     ]
    }
   ],
   "source": [
    "# Display results for all models\n",
    "headers = [\"Model\", \"MSE\", \"R-Squared\"]\n",
    "print(tabulate(results, headers=headers))\n",
    "\n",
    "# Sort models by closeness to RMSE value of 1\n",
    "results.sort(key=lambda x: abs(np.sqrt(x[1]) - 1))\n",
    "\n",
    "# Filter models with RMSE closest to 1\n",
    "close_models = [(name, mse, r_squared) for name, mse, r_squared in results]\n",
    "\n",
    "# Print models with RMSE closest to 1\n",
    "if close_models:\n",
    "    print(\"\\nModels with RMSE closest to 1:\")\n",
    "    print(tabulate(close_models[:3], headers=headers))\n",
    "else:\n",
    "    print(\"No models found within the specified RMSE threshold.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack the models to obtain better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;random_forest&#x27;,\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     (&#x27;xgboost&#x27;,\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   device=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   grow...\n",
       "                                                                   multi_strategy=None,\n",
       "                                                                   n_estimators=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={&#x27;random_forest__max_depth&#x27;: [10, 20],\n",
       "                         &#x27;random_forest__n_estimators&#x27;: [100, 150],\n",
       "                         &#x27;xgboost__learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;xgboost__max_depth&#x27;: [3, 5],\n",
       "                         &#x27;xgboost__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;random_forest&#x27;,\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     (&#x27;xgboost&#x27;,\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   device=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   grow...\n",
       "                                                                   multi_strategy=None,\n",
       "                                                                   n_estimators=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={&#x27;random_forest__max_depth&#x27;: [10, 20],\n",
       "                         &#x27;random_forest__n_estimators&#x27;: [100, 150],\n",
       "                         &#x27;xgboost__learning_rate&#x27;: [0.1, 0.01],\n",
       "                         &#x27;xgboost__max_depth&#x27;: [3, 5],\n",
       "                         &#x27;xgboost__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;random_forest&#x27;, RandomForestRegressor()),\n",
       "                              (&#x27;xgboost&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type...\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=None, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...))],\n",
       "                  final_estimator=LinearRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>random_forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=StackingRegressor(estimators=[('random_forest',\n",
       "                                                      RandomForestRegressor()),\n",
       "                                                     ('xgboost',\n",
       "                                                      XGBRegressor(base_score=None,\n",
       "                                                                   booster=None,\n",
       "                                                                   callbacks=None,\n",
       "                                                                   colsample_bylevel=None,\n",
       "                                                                   colsample_bynode=None,\n",
       "                                                                   colsample_bytree=None,\n",
       "                                                                   device=None,\n",
       "                                                                   early_stopping_rounds=None,\n",
       "                                                                   enable_categorical=False,\n",
       "                                                                   eval_metric=None,\n",
       "                                                                   feature_types=None,\n",
       "                                                                   gamma=None,\n",
       "                                                                   grow...\n",
       "                                                                   multi_strategy=None,\n",
       "                                                                   n_estimators=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   num_parallel_tree=None,\n",
       "                                                                   random_state=None, ...))],\n",
       "                                         final_estimator=LinearRegression()),\n",
       "             param_grid={'random_forest__max_depth': [10, 20],\n",
       "                         'random_forest__n_estimators': [100, 150],\n",
       "                         'xgboost__learning_rate': [0.1, 0.01],\n",
       "                         'xgboost__max_depth': [3, 5],\n",
       "                         'xgboost__n_estimators': [100, 150]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base models\n",
    "base_models = [\n",
    "    ('random_forest', RandomForestRegressor()),\n",
    "    ('xgboost', XGBRegressor())\n",
    "]\n",
    "\n",
    "# Create a stacking regressor with the specified base models and a final estimator (Linear Regression)\n",
    "stacking_regressor = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
    "\n",
    "# Define a more limited parameter grid for tuning\n",
    "param_grid = {\n",
    "    'random_forest__n_estimators': [100, 150],\n",
    "    'random_forest__max_depth': [10, 20],\n",
    "    'xgboost__n_estimators': [100, 150],\n",
    "    'xgboost__max_depth': [3, 5],\n",
    "    'xgboost__learning_rate': [0.1, 0.01],\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(stacking_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Combination:\n",
      "Parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 150, 'xgboost__learning_rate': 0.1, 'xgboost__max_depth': 3, 'xgboost__n_estimators': 150}\n",
      "Mean Test Score (neg MSE): -12.121211076219595\n",
      "Final Metrics for the Best Combination:\n",
      "MSE: 8.203276172449613\n",
      "R^2 Score: 0.8899082623003092\n"
     ]
    }
   ],
   "source": [
    "# Get the best combination based on the mean_test_score\n",
    "best_combination_index = grid_search.best_index_\n",
    "best_combination_params = grid_search.cv_results_['params'][best_combination_index]\n",
    "best_combination_mean_test_score = grid_search.cv_results_['mean_test_score'][best_combination_index]\n",
    "\n",
    "# Set the best parameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_combination_params)\n",
    "\n",
    "# Fit the stacking regressor with the best parameters on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set with the best stacking regressor\n",
    "y_pred_stacking = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Calculate final metrics\n",
    "mse_stacking = mean_squared_error(y_test, y_pred_stacking)\n",
    "r2_stacking = r2_score(y_test, y_pred_stacking)\n",
    "\n",
    "# Print the best combination and its metrics\n",
    "print(\"\\nBest Combination:\")\n",
    "print(f\"Parameters: {best_combination_params}\")\n",
    "print(f\"Mean Test Score (neg MSE): {best_combination_mean_test_score}\")\n",
    "print(\"Final Metrics for the Best Combination:\")\n",
    "print(\"MSE:\", mse_stacking)\n",
    "print(\"R^2 Score:\", r2_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted\n",
      "173    23.6  23.543390\n",
      "274    32.4  31.446933\n",
      "491    13.6  16.085124\n",
      "72     22.8  23.998505\n",
      "452    16.1  17.633155\n",
      "..      ...        ...\n",
      "441    17.1  13.017324\n",
      "23     14.5  14.107064\n",
      "225    50.0  44.615786\n",
      "433    14.3  16.167190\n",
      "447    12.6  17.039876\n",
      "\n",
      "[152 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choose the best combination of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the best hyperparameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_params)\n",
    "\n",
    "# Fit the stacking regressor on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_stacking = stacking_regressor.predict(X_test)\n",
    "\n",
    "# Compare predictions with original values\n",
    "predictions_comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_stacking})\n",
    "print(predictions_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling The Model file For Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best combination of hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Set the best hyperparameters to the stacking regressor\n",
    "stacking_regressor.set_params(**best_params)\n",
    "\n",
    "# Fit the stacking regressor on the entire training set\n",
    "stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Save the model with the best parameters\n",
    "pickle.dump(stacking_regressor, open('newregmodel.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Validation Set: [23.49598379 31.4182662  16.05124193 24.01286022 17.64187457 22.51098589\n",
      " 18.26764595 14.27383529 21.05971863 21.03739103 20.22354749 18.85673811\n",
      "  6.9694728  21.76658815 19.83380524 24.85896574 19.34245913  9.07041211\n",
      " 46.00216477 16.51095906 24.33633689 25.10950472 13.75779361 20.74196481\n",
      " 15.14265098 16.08307783 22.03020445 14.03847566 20.04026945 21.3449875\n",
      " 19.67877351 23.56386576 21.097059   20.39144489 14.60713992 16.08644247\n",
      " 33.66550887 19.3815015  21.4945998  23.86614816 17.38989579 29.77024116\n",
      " 45.2879043  20.28471442 22.54351007 14.2707451  16.32685676 23.69170576\n",
      " 18.12952695 27.69445317 20.94045625 37.32333368 16.27878451 25.81558923\n",
      " 48.4746817  21.79225483 15.73243844 32.28191825 21.8934844  18.2913748\n",
      " 22.36834136 34.3924179  31.27821493 19.06186594 24.02787128 18.4568207\n",
      " 13.95346818 23.74226321 28.44770162 14.71200015 21.30304427 26.04858185\n",
      " 11.36688259 21.50144945 22.44399049  5.00696281 20.78995092 45.32479879\n",
      " 10.82939753 12.50447964 22.14208039 11.6143824  19.2650703  10.51059084\n",
      " 20.06120176 26.70949953 16.03107729 23.77961707 25.62112413 17.05023584\n",
      " 22.1330004   8.44116975 19.82708079 19.42725725 22.82410355 19.98766538\n",
      " 40.52904088 10.31655955 12.62369555 10.97913391 20.19561936 23.43169724\n",
      " 13.78245775 20.54615107 20.00706951 10.75156273 19.00760485 26.37210449\n",
      " 20.07790368 24.13098193  8.19165748 13.72924031 22.25692717 25.70502392\n",
      " 32.86165977 16.16294652 42.00195453 15.31606203 20.71108705 24.45725444\n",
      " 19.12782214 24.21128425  5.72239263 20.72659013 23.92156215 22.36567826\n",
      " 22.86817565 40.09488487 16.44593854 47.38738652 16.86231377 23.58321061\n",
      " 19.46409855 18.82102205 13.40642289 20.52746777 21.11630886 31.06913446\n",
      " 29.02962715 15.98465415 17.41718944 24.98070672 20.23581601 18.72028746\n",
      "  6.81021589 21.33401698 16.90192229 13.0012136  14.098746   44.67336175\n",
      " 16.12365648 17.02692446]\n"
     ]
    }
   ],
   "source": [
    "# Load the StackingRegressor model from the existing pickled file\n",
    "loaded_stacking_regressor = pickle.load(open('newregmodel.pkl', 'rb'))\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_validation = loaded_stacking_regressor.predict(X_test)\n",
    "\n",
    "# Save the new model with a different pickle name\n",
    "new_pickle_name = 'new_regmodel.pkl'\n",
    "pickle.dump(loaded_stacking_regressor, open(new_pickle_name, 'wb'))\n",
    "\n",
    "# Print the predictions (y_pred_validation) or use them as needed\n",
    "print(\"Predictions on Validation Set:\", y_pred_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
